Resource-Aware Automata Selection SystemðŸŒ¿ Green Computing meets Theoretical Computer ScienceThis project implements a hardware-validated framework to optimize the execution of formal languages (Regular, Context-Free, and Context-Sensitive) based on physical energy consumption. By benchmarking Deterministic Finite Automata (DFA) and Pushdown Automata (PDA) on actual hardware (HP Omen), this system trains an XGBoost Classifier to predict the most energy-efficient computational model for a given input string.ðŸš€ System ArchitectureThe system operates in four distinct phases:Dataset Generation: Creates 30,000 samples spanning the Chomsky Hierarchy (Parity, Dyck, and $a^n b^n c^n$).Hardware Benchmarking: Utilizes Intel RAPL via pyrapl to measure real-time CPU energy (Joules).Noise Injection: Introduces ambiguous cases where theoretical models (PDA) are out-performed by simpler models (DFA) due to "Stack Initialization Taxes."Predictive Modeling: An XGBoost model learns to predict the optimal_model based on structural DNA.ðŸ“Š Dataset Schema (14 Columns)The model is trained on the following features extracted from each string:FeatureDescriptionsequenceThe raw input string.language_nameThe class of language (Parity, Dyck, etc.).alphabet_sizeNumber of unique symbols.max_nesting_depthDeepest stack level reached.is_ambiguousBoolean flag for multiple parse trees.complexityEstimated computational difficulty.dfa_energy / pda_energyPhysical energy consumption measured in Joules.optimal_modelTarget Label: 0 (DFA), 1 (PDA), 2 (TM).ðŸ“ˆ Performance & Logic (The 98% Goal)Unlike theoretical models that assume 100% accuracy based on grammar rules, this system accounts for Hardware Anomalies:The "Stack Tax": For short strings (e.g., ()), the energy cost of initializing a PDA stack exceeds the cost of a simple DFA transition.The "Cache Miss": Large state-transition tables in DFAs can cause CPU cache misses, making a PDA more efficient for long, simple sequences.ðŸ›  Usage1. Benchmarking (Requires sudo for hardware access)Bashsudo ./venv/bin/python benchmarker.py
2. Inject Noise (Simulate Real-World Overlap)Bashpython inject_noise.py
3. Train the BrainBashpython train_model.py
ðŸ“œ Patent SignificanceThis framework identifies the "Computational Equilibrium Point"â€”the exact threshold where a system should switch from a Finite State Machine to a Pushdown Automaton to minimize carbon footprint and power draw in high-scale data processing.